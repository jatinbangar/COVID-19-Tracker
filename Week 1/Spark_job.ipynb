{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#### Install pyspark library under this venv using command\n",
    "<code>python -m pip install pyspark</code>\n",
    "\n",
    "#### Install jupyter notebook under this venv\n",
    "<code>python -m pip install notebook</code>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Import SparkSession Class from pyspark.sql"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "source": [
    "#### Create a SparkSession Object to start working on Dataframes using local mode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    master(\"local\"). \\\n",
    "    appName(\"COVID-19-Tracker\"). \\\n",
    "    getOrCreate()\n",
    "\n",
    "print(type(spark))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pyspark.sql.session.SparkSession'>\n"
     ]
    }
   ]
  },
  {
   "source": [
    "#### Import Public Health Infobase data into phi_df Dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(pruid=35, prname='Ontario', prnameFR='Ontario', date='31-01-2020', update=None, numconf=3, numprob=0, numdeaths=0, numtotal=3, numtested=None, numtests=None, numrecover=None, percentrecover=None, ratetested=None, ratetests=None, numtoday=3, percentoday=300.0, ratetotal=0.02, ratedeaths=0.0, numdeathstoday=0.0, percentdeath=0.0, numtestedtoday=None, numteststoday=None, numrecoveredtoday=None, percentactive=100.0, numactive=3, rateactive=0.02, numtotal_last14=None, ratetotal_last14=None, numdeaths_last14=None, ratedeaths_last14=None, numtotal_last7=None, ratetotal_last7=None, numdeaths_last7=None, ratedeaths_last7=None, avgtotal_last7=None, avgincidence_last7=None, avgdeaths_last7=None, avgratedeaths_last7=None),\n",
       " Row(pruid=59, prname='British Columbia', prnameFR='Colombie-Britannique', date='31-01-2020', update=None, numconf=1, numprob=0, numdeaths=0, numtotal=1, numtested=None, numtests=None, numrecover=None, percentrecover=None, ratetested=None, ratetests=None, numtoday=1, percentoday=100.0, ratetotal=0.02, ratedeaths=0.0, numdeathstoday=0.0, percentdeath=0.0, numtestedtoday=None, numteststoday=None, numrecoveredtoday=None, percentactive=100.0, numactive=1, rateactive=0.02, numtotal_last14=None, ratetotal_last14=None, numdeaths_last14=None, ratedeaths_last14=None, numtotal_last7=None, ratetotal_last7=None, numdeaths_last7=None, ratedeaths_last7=None, avgtotal_last7=None, avgincidence_last7=None, avgdeaths_last7=None, avgratedeaths_last7=None),\n",
       " Row(pruid=1, prname='Canada', prnameFR='Canada', date='31-01-2020', update=None, numconf=4, numprob=0, numdeaths=0, numtotal=4, numtested=None, numtests=None, numrecover=None, percentrecover=None, ratetested=None, ratetests=None, numtoday=4, percentoday=400.0, ratetotal=0.01, ratedeaths=0.0, numdeathstoday=0.0, percentdeath=0.0, numtestedtoday=None, numteststoday=None, numrecoveredtoday=None, percentactive=100.0, numactive=4, rateactive=0.01, numtotal_last14=None, ratetotal_last14=None, numdeaths_last14=None, ratedeaths_last14=None, numtotal_last7=None, ratetotal_last7=None, numdeaths_last7=None, ratedeaths_last7=None, avgtotal_last7=None, avgincidence_last7=None, avgdeaths_last7=None, avgratedeaths_last7=None),\n",
       " Row(pruid=35, prname='Ontario', prnameFR='Ontario', date='08-02-2020', update=None, numconf=3, numprob=0, numdeaths=0, numtotal=3, numtested=None, numtests=None, numrecover=None, percentrecover=None, ratetested=None, ratetests=None, numtoday=0, percentoday=0.0, ratetotal=0.02, ratedeaths=0.0, numdeathstoday=0.0, percentdeath=0.0, numtestedtoday=None, numteststoday=None, numrecoveredtoday=None, percentactive=100.0, numactive=3, rateactive=0.02, numtotal_last14=None, ratetotal_last14=None, numdeaths_last14=None, ratedeaths_last14=None, numtotal_last7=None, ratetotal_last7=None, numdeaths_last7=None, ratedeaths_last7=None, avgtotal_last7=None, avgincidence_last7=None, avgdeaths_last7=None, avgratedeaths_last7=None),\n",
       " Row(pruid=59, prname='British Columbia', prnameFR='Colombie-Britannique', date='08-02-2020', update=None, numconf=4, numprob=0, numdeaths=0, numtotal=4, numtested=None, numtests=None, numrecover=None, percentrecover=None, ratetested=None, ratetests=None, numtoday=3, percentoday=300.0, ratetotal=0.08, ratedeaths=0.0, numdeathstoday=0.0, percentdeath=0.0, numtestedtoday=None, numteststoday=None, numrecoveredtoday=None, percentactive=100.0, numactive=4, rateactive=0.08, numtotal_last14=None, ratetotal_last14=None, numdeaths_last14=None, ratedeaths_last14=None, numtotal_last7=None, ratetotal_last7=None, numdeaths_last7=None, ratedeaths_last7=None, avgtotal_last7=None, avgincidence_last7=None, avgdeaths_last7=None, avgratedeaths_last7=None)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "phi_df = spark. \\\n",
    "    read. \\\n",
    "    format(\"csv\"). \\\n",
    "    option(\"inferSchema\",\"true\"). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    load(\"CA__covid19__latest.csv\")\n",
    "\n",
    "phi_df.take(5)"
   ]
  },
  {
   "source": [
    "#### Importing useful attributes to our PHI dataframe and performing sort operation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(phi_Date='08-03-2020', phi_Province='Alberta', phi_Confirmed=1, phi_Deaths=0),\n",
       " Row(phi_Date='09-03-2020', phi_Province='Alberta', phi_Confirmed=7, phi_Deaths=0),\n",
       " Row(phi_Date='11-03-2020', phi_Province='Alberta', phi_Confirmed=14, phi_Deaths=0),\n",
       " Row(phi_Date='12-03-2020', phi_Province='Alberta', phi_Confirmed=19, phi_Deaths=0),\n",
       " Row(phi_Date='13-03-2020', phi_Province='Alberta', phi_Confirmed=23, phi_Deaths=0)]"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "phi_df1 = phi_df.select(phi_df.date.alias('phi_Date'), \\\n",
    "                        phi_df.prname.alias('phi_Province'), \\\n",
    "                        phi_df.numconf.alias('phi_Confirmed'), \\\n",
    "                        phi_df.numdeaths.alias('phi_Deaths') \\\n",
    "                       ). \\\n",
    "                 orderBy('phi_Province', 'phi_Confirmed', 'phi_Date')\n",
    "\n",
    "phi_df1.take(5)"
   ]
  },
  {
   "source": [
    "#### Import data_format and to_date functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, to_date"
   ]
  },
  {
   "source": [
    "#### Update date attribute in our PHI dataframe to yyyy-MM-dd format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(phi_Date='2020-03-08', phi_Province='Alberta', phi_Confirmed=1, phi_Deaths=0),\n",
       " Row(phi_Date='2020-03-09', phi_Province='Alberta', phi_Confirmed=7, phi_Deaths=0),\n",
       " Row(phi_Date='2020-03-11', phi_Province='Alberta', phi_Confirmed=14, phi_Deaths=0),\n",
       " Row(phi_Date='2020-03-12', phi_Province='Alberta', phi_Confirmed=19, phi_Deaths=0),\n",
       " Row(phi_Date='2020-03-13', phi_Province='Alberta', phi_Confirmed=23, phi_Deaths=0)]"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "phi_df2 = phi_df1.withColumn(\"phi_Date\", date_format(to_date(phi_df1.phi_Date, \"dd-MM-yyyy\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "phi_df2.take(5)"
   ]
  },
  {
   "source": [
    "#### Filter for PHI dataframe where province attribute does not contain Repatriated travellers and Canada"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|        phi_Province|\n+--------------------+\n|            Manitoba|\n|               Yukon|\n|         Nova Scotia|\n|Northwest Territo...|\n|Newfoundland and ...|\n|             Alberta|\n|             Nunavut|\n|       New Brunswick|\n|        Saskatchewan|\n|Prince Edward Island|\n|             Ontario|\n|    British Columbia|\n|              Quebec|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "phi_df3 = phi_df2.where(\"phi_Province NOT IN ('Repatriated travellers', 'Canada')\")\n",
    "\n",
    "phi_df3.select(\"phi_Province\").distinct().show()"
   ]
  },
  {
   "source": [
    "#### Import John Hopkins data into jh_df Dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(jh_Date=datetime.date(2020, 1, 22), jh_Country='Afghanistan', jh_Province=None, jh_Lat=0.0, jh_Long=0.0, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None),\n",
       " Row(jh_Date=datetime.date(2020, 1, 23), jh_Country='Afghanistan', jh_Province=None, jh_Lat=0.0, jh_Long=0.0, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None),\n",
       " Row(jh_Date=datetime.date(2020, 1, 24), jh_Country='Afghanistan', jh_Province=None, jh_Lat=0.0, jh_Long=0.0, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None),\n",
       " Row(jh_Date=datetime.date(2020, 1, 25), jh_Country='Afghanistan', jh_Province=None, jh_Lat=0.0, jh_Long=0.0, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None),\n",
       " Row(jh_Date=datetime.date(2020, 1, 26), jh_Country='Afghanistan', jh_Province=None, jh_Lat=0.0, jh_Long=0.0, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None)]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "jh_df = spark. \\\n",
    "    read. \\\n",
    "    format(\"csv\"). \\\n",
    "    schema(\"jh_Date date, jh_Country string, jh_Province string, jh_Lat double, jh_Long double, jh_Confirmed            integer, jh_Recovered integer, jh_Deaths integer\"). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    load(\"time-series-19-covid-combined.csv\")\n",
    "\n",
    "jh_df.take(5)"
   ]
  },
  {
   "source": [
    "#### Filter John Hopkins dataframe for Canada records only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(jh_Date=datetime.date(2020, 1, 22), jh_Country='Canada', jh_Province='Alberta', jh_Lat=0.0, jh_Long=None, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None),\n",
       " Row(jh_Date=datetime.date(2020, 1, 23), jh_Country='Canada', jh_Province='Alberta', jh_Lat=0.0, jh_Long=None, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None),\n",
       " Row(jh_Date=datetime.date(2020, 1, 24), jh_Country='Canada', jh_Province='Alberta', jh_Lat=0.0, jh_Long=None, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None),\n",
       " Row(jh_Date=datetime.date(2020, 1, 25), jh_Country='Canada', jh_Province='Alberta', jh_Lat=0.0, jh_Long=None, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None),\n",
       " Row(jh_Date=datetime.date(2020, 1, 26), jh_Country='Canada', jh_Province='Alberta', jh_Lat=0.0, jh_Long=None, jh_Confirmed=0, jh_Recovered=None, jh_Deaths=None)]"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "jh_df1 = jh_df.filter(jh_df.jh_Country == 'Canada')\n",
    "\n",
    "jh_df1.take(5)"
   ]
  },
  {
   "source": [
    "#### Filter for John Hopkins dataframe where province attribute does not contain Repatriated travellers, Grand Princess and Diamond Princess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|         jh_Province|\n+--------------------+\n|            Manitoba|\n|               Yukon|\n|         Nova Scotia|\n|Northwest Territo...|\n|Newfoundland and ...|\n|             Alberta|\n|             Nunavut|\n|       New Brunswick|\n|        Saskatchewan|\n|Prince Edward Island|\n|             Ontario|\n|    British Columbia|\n|              Quebec|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "jh_df2 = jh_df1.where(\"jh_Province NOT IN ('Repatriated Travellers', 'Grand Princess', 'Diamond Princess')\")\n",
    "\n",
    "jh_df2.select(\"jh_Province\").distinct().show()"
   ]
  },
  {
   "source": [
    "#### Performing join operation for matching date and province attributes for PHI and John Hopkins dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLeftOuterJoin = phi_df3. \\\n",
    "    join(jh_df2, \\\n",
    "         (phi_df3.phi_Date == jh_df2.jh_Date) & (phi_df3.phi_Province == jh_df2.jh_Province), \\\n",
    "             'left' \\\n",
    "        )"
   ]
  },
  {
   "source": [
    "#### Our final dataframe contains records for the number of confirmed cases, number of recovered cases and the number of deaths from COVID-19 virus in Canada till date"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final = dfLeftOuterJoin.select(dfLeftOuterJoin.phi_Date.alias('Date'), \\\n",
    "                                  dfLeftOuterJoin.jh_Country.alias('Country'), \\\n",
    "                                  dfLeftOuterJoin.phi_Province.alias('Province'), \\\n",
    "                                  dfLeftOuterJoin.jh_Lat.alias('Latitude'), \\\n",
    "                                  dfLeftOuterJoin.jh_Long.alias('Longitude'), \\\n",
    "                                  dfLeftOuterJoin.phi_Confirmed.alias('Confirmed'), \\\n",
    "                                  dfLeftOuterJoin.jh_Recovered.alias('Recovered'), \\\n",
    "                                  dfLeftOuterJoin.jh_Deaths.alias('Deaths') \\\n",
    "                                 ) \\\n",
    "                          .orderBy(\"Province\", \"Date\", \"Confirmed\")"
   ]
  },
  {
   "source": [
    "#### Write our dataframe in csv format in a new directory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final.write. \\\n",
    "    format(\"csv\"). \\\n",
    "    mode(\"overwrite\"). \\\n",
    "    save(\"output_path\")"
   ]
  }
 ]
}