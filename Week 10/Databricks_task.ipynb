{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "irish-ecuador",
   "metadata": {},
   "source": [
    "#### What is Databricks SQL Analytics?\n",
    "* Databricks offers the convenience to build notebooks in Databricks Workspace using the SQL language, perform queries on data, build visualizations, build dashboards and connect to various BI tools. It offers up to 9X better price/performance for BI and reporting workloads.\n",
    "\n",
    "\n",
    "* Advantages:\n",
    "    - SQL-native user interface for data analytics \n",
    "    - Built in connectors for existing BI tools\n",
    "    - Fine-grained performance\n",
    "    - Fast query performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-portsmouth",
   "metadata": {},
   "source": [
    "#### Databricks workspace deployment on AWS\n",
    "<img src='Databricks_Architecture.png' width=700>\n",
    "\n",
    "* Create a cross-account role and an access policy in AWS.\n",
    "    * In the AWS Console, go to IAM Services.\n",
    "    * Under the Create role option, Choose the option Another AWS account .Enter the databricks account ID.\n",
    "    <img src='Create_Role.png' width=700>\n",
    "    * Under permissions Add the following inline JSON policy.\n",
    "    <code>\n",
    "    {\n",
    "      \"Version\": \"2012-10-17\",\n",
    "      \"Statement\": [\n",
    "        {\n",
    "          \"Sid\": \"Stmt1403287045000\",\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Action\": [\n",
    "              \"ec2:AssociateDhcpOptions\",\n",
    "              \"ec2:AssociateIamInstanceProfile\",\n",
    "              \"ec2:AssociateRouteTable\",\n",
    "              \"ec2:AttachInternetGateway\",\n",
    "              \"ec2:AttachVolume\",\n",
    "              \"ec2:AuthorizeSecurityGroupEgress\",\n",
    "              \"ec2:AuthorizeSecurityGroupIngress\",\n",
    "              \"ec2:CancelSpotInstanceRequests\",\n",
    "              \"ec2:CreateDhcpOptions\",\n",
    "              \"ec2:CreateInternetGateway\",\n",
    "              \"ec2:CreateKeyPair\",\n",
    "              \"ec2:CreatePlacementGroup\",\n",
    "              \"ec2:CreateRoute\",\n",
    "              \"ec2:CreateSecurityGroup\",\n",
    "              \"ec2:CreateSubnet\",\n",
    "              \"ec2:CreateTags\",\n",
    "              \"ec2:CreateVolume\",\n",
    "              \"ec2:CreateVpc\",\n",
    "              \"ec2:CreateVpcPeeringConnection\",\n",
    "              \"ec2:DeleteInternetGateway\",\n",
    "              \"ec2:DeleteKeyPair\",\n",
    "              \"ec2:DeletePlacementGroup\",\n",
    "              \"ec2:DeleteRoute\",\n",
    "              \"ec2:DeleteRouteTable\",\n",
    "              \"ec2:DeleteSecurityGroup\",\n",
    "              \"ec2:DeleteSubnet\",\n",
    "              \"ec2:DeleteTags\",\n",
    "              \"ec2:DeleteVolume\",\n",
    "              \"ec2:DeleteVpc\",\n",
    "              \"ec2:DescribeAvailabilityZones\",\n",
    "              \"ec2:DescribeIamInstanceProfileAssociations\",\n",
    "              \"ec2:DescribeInstanceStatus\",\n",
    "              \"ec2:DescribeInstances\",\n",
    "              \"ec2:DescribePlacementGroups\",\n",
    "              \"ec2:DescribePrefixLists\",\n",
    "              \"ec2:DescribeReservedInstancesOfferings\",\n",
    "              \"ec2:DescribeRouteTables\",\n",
    "              \"ec2:DescribeSecurityGroups\",\n",
    "              \"ec2:DescribeSpotInstanceRequests\",\n",
    "              \"ec2:DescribeSpotPriceHistory\",\n",
    "              \"ec2:DescribeSubnets\",\n",
    "              \"ec2:DescribeVolumes\",\n",
    "              \"ec2:DescribeVpcs\",\n",
    "              \"ec2:DetachInternetGateway\",\n",
    "              \"ec2:DisassociateIamInstanceProfile\",\n",
    "              \"ec2:ModifyVpcAttribute\",\n",
    "              \"ec2:ReplaceIamInstanceProfileAssociation\",\n",
    "              \"ec2:RequestSpotInstances\",\n",
    "              \"ec2:RevokeSecurityGroupEgress\",\n",
    "              \"ec2:RevokeSecurityGroupIngress\",\n",
    "              \"ec2:RunInstances\",\n",
    "              \"ec2:TerminateInstances\"\n",
    "          ],\n",
    "          \"Resource\": [\n",
    "            \"*\"\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Action\": [\n",
    "            \"iam:CreateServiceLinkedRole\",\n",
    "            \"iam:PutRolePolicy\"\n",
    "          ],\n",
    "          \"Resource\": \"arn:aws:iam::*:role/aws-service-role/spot.amazonaws.com/AWSServiceRoleForEC2Spot\",\n",
    "          \"Condition\": {\n",
    "            \"StringLike\": {\n",
    "              \"iam:AWSServiceName\": \"spot.amazonaws.com\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    </code>\n",
    "    \n",
    "    - Review policy enter a policy name and click on Create Policy.\n",
    "    - In the role summary, Copy the Role ARN.\n",
    "\n",
    "* Go to your databricks account and under the AWS Account settings, paste your Role ARN.\n",
    "<img src='Role_ARN.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-judge",
   "metadata": {},
   "source": [
    "#### Getting Started as a Databricks Workspace User / Deploying a Cluster\n",
    "* Once you are in the databricks Workspace, Choose Clusters tab and Create Cluster option.\n",
    "<img src='Deploy_Cluster.png' width=700>\n",
    "* Under New Cluster option Databricks Runtime Version 7.3 which has support for Spark 3.0.1.\n",
    "* Choose the Worker Node type. I have chosen m5a.xlarge which offers 16GB memory and 4 vCPUs.\n",
    "<img src='Create_Cluster.png' width=700>\n",
    "* Review parameters and click Create Cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-testimony",
   "metadata": {},
   "source": [
    "#### Create a new notebook\n",
    "* Once your cluster is up and running, Choose the workspace tab, Under the option Workspace and under Create choose Notebook.\n",
    "<img src='Create_Notebook.png' width=700>\n",
    "* Give name to your notebook. Choose the default language as Python and select the newly created Cluster my-spark-cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-pride",
   "metadata": {},
   "source": [
    "#### Create a Spark SQL table from CSV data\n",
    "* Click the Data tab and click Add Data. \n",
    "* Under Data source section choose Upload file. This will upload your file under the DBFS Target directory /FileStore/tables/.\n",
    "<img src='Create_Table.png' width=700>\n",
    "* Run the following code to create a Spark SQL table from your CSV file.\n",
    "<code>\n",
    "%sql\n",
    "DROP TABLE IF EXISTS covid_CA;\n",
    "CREATE TABLE covid_CA USING CSV OPTIONS (path \"/FileStore/tables/CA__covid19__latest.csv\", header \"true\")\n",
    "</code>\n",
    "<img src='SQL_Table.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-typing",
   "metadata": {},
   "source": [
    "#### Querying the table using SparkSQL\n",
    "* Printing the records.\n",
    "<code>\n",
    "%sql\n",
    "SELECT * FROM covid_CA ORDER BY date DESC\n",
    "</code>\n",
    "<img src='SparkSQL_Query.png' width=700>\n",
    "* Get the number of Confirmed Cases for each province.\n",
    "<code>\n",
    "%sql\n",
    "SELECT prname AS Province, sum(numtoday) AS Number_of_Confirmed_Cases \n",
    "FROM covid_CA \n",
    "GROUP BY prname \n",
    "ORDER BY sum(numtoday) DESC\n",
    "</code>\n",
    "<img src='SparkSQL_Query2.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-blank",
   "metadata": {},
   "source": [
    "#### Querying the table by creating Spark dataframe\n",
    "* Create a Spark Dataframe from CSV file.\n",
    "<code>\n",
    "covid_CA_df = spark.read.csv(\"/FileStore/tables/CA__covid19__latest.csv\", header=\"true\", inferSchema=\"true\")\n",
    "</code>\n",
    "<img src='Dataframe_Query.png' width=700>\n",
    "* Printing the records using PySpark dataframe.\n",
    "<code>\n",
    "covid_CA_df.display()\n",
    "</code>\n",
    "<img src='Dataframe_Query2.png' width=700>\n",
    "* Get the Number of Confirmed Cases for Each Province using PySpark Dataframe.\n",
    "<code>\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "\n",
    "covid_CA_df \\\n",
    "  .groupBy('prname') \\\n",
    "  .agg(_sum('numtoday').alias('Total Confirmed Cases')) \\\n",
    "  .orderBy(_sum('numtoday').desc()) \\\n",
    "  .show()\n",
    "</code>\n",
    "<img src='Dataframe_Query3.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-messenger",
   "metadata": {},
   "source": [
    "#### Visualize the data for insights\n",
    "* Databricks supports various types of visualizations out of the box using the display and displayHTML functions.\n",
    "<code>\n",
    "display(\n",
    "  covid_CA_df \\\n",
    "    .groupBy('prname') \\\n",
    "    .agg(_sum('numtoday').alias('Total Confirmed Cases')) \\\n",
    "    .orderBy(_sum('numtoday').desc())\n",
    ")\n",
    "</code>\n",
    "<img src='Visualize.png' width=700>\n",
    "* Click the arrow near the Bar Chart Icon.\n",
    "<img src='Visualize2.png' width=700>\n",
    "* Choose Bar option.\n",
    "<img src='Visualize3.png' width=700>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
