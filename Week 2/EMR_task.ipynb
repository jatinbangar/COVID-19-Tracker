{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login to the AWS Management Console and under the Analytics section choose EMR. Then follow the below steps under EMR service\n",
    "* Go to Create Cluster.\n",
    "* Go to Advanced Options.\n",
    "* Under Software Configuration section, choose emr-5.32.0 as the Release and choose your software. I have checked Hadoop 2.10.1, Hive 2.3.7 and Spark 2.4.7. Click on Next.\n",
    "* Under Cluster Nodes and Instances section, choose 1 m5a.xlarge Master and 2 m5a.xlarge Core Nodes. You can additionally choose Task nodes if you do not want Core Nodes to perform compute. Click on Next.\n",
    "* Give a name to your cluster. In my case I have named it as Spark Cluster. Enable logging on your cluster and choose an S3 folder to save your logs.\n",
    "* Under Bootstrap actions, add your bootstrap script. In my case it is bootstrap_EMR.sh stored under the path s3://covid-19-tracker-2020/bootstrap/.\n",
    "The Bootstrap script contains the following bootstrap code:\n",
    "    <code>\n",
    "    #!/bin/bash\n",
    "    aws s3 cp s3://covid-19-tracker-2020/data/CA__covid19__latest.csv /home/hadoop/data/\n",
    "    aws s3 cp s3://covid-19-tracker-2020/data/time-series-19-covid-combined.csv /home/hadoop/data/\n",
    "    aws s3 cp s3://covid-19-tracker-2020/python/Spark-Job.py /home/hadoop/python/\n",
    "    </code>\n",
    "    \n",
    "* Choose your custom EC2 Key pair. \n",
    "* Click on Create Cluster.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSH into your EC2 cluster and perform the following steps\n",
    "* Make a new directory in the hdfs file system\n",
    "    <code>\n",
    "    hdfs dfs -mkdir /user/hadoop/data/\n",
    "    </code>\n",
    "\n",
    "* Copy the data files from the local linux system to HDFS\n",
    "    <code>\n",
    "    hdfs dfs -put /home/hadoop/data/CA__covid19__latest.csv /user/hadoop/data/\n",
    "    hdfs dfs -put /home/hadoop/data/time-series-19-covid-combined.csv /user/hadoop/data/\n",
    "    </code>\n",
    "    \n",
    "* Updates to our Spark-Job.py python Script\n",
    "    <code>\n",
    "    spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName(\"Covid Tracker\"). \\ \n",
    "    getOrCreate()#We remove the master(“local”) option as we building Spark Session object on the cluster in         place of our local machine\n",
    "    </code>\n",
    "    <code>\n",
    "    phi_df = spark. \\\n",
    "    read. \\\n",
    "    format(\"csv\"). \\\n",
    "    option(\"inferSchema\",\"true\"). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    load(\"/user/hadoop/data/CA__covid19__latest.csv\")#In place of local machine path we provide HDFS path\n",
    "    </code>\n",
    "    <code>\n",
    "    jh_df = spark. \\\n",
    "    read. \\\n",
    "    format(\"csv\"). \\\n",
    "    schema(\"jh_Date date, jh_Country string, jh_Province string, jh_Lat double, jh_Long double, jh_Confirmed integer, \\\n",
    "    jh_Recovered integer, jh_Deaths integer\"). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    load(\"/user/hadoop/data/time-series-19-covid-combined.csv\")#HDFS path containing our source data\n",
    "    </code>\n",
    "    <code>\n",
    "    df_Final.write. \\\n",
    "    format(\"csv\"). \\\n",
    "    mode(\"overwrite\"). \\\n",
    "    save(\"s3://covid-19-tracker-2020/output/tracker_results/\")#Provide the output path as the AWS S3 directory\n",
    "    </code>\n",
    "\n",
    "    The remaining of the code remains the same\n",
    "* Run python job using the below command\n",
    "    <code>\n",
    "    spark-submit /home/hadoop/python/Spark-Job-EMR.py\n",
    "    </code>\n",
    "    \n",
    "* Output file containing the COVID-19 tracking for Canada Is located in the below location\n",
    "\n",
    "    https://covid-19-tracker-2020.s3.amazonaws.com/output/tracker_results/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
